---
title: CS231N学习笔记
tags: CS231N
mathjax: true
abbrlink: 24704
date: 2019-09-24 10:39:11
---
## CS231N课程描述和资源
CS231n的全称是CS231n: Convolutional Neural Networks for Visual Recognition，即面向视觉识别的卷积神经网络。该课程是斯坦福大学计算机视觉实验室推出的课程。
课程官网：http://cs231n.stanford.edu/
官方笔记：http://cs231n.github.io/
B站视频：https://www.bilibili.com/video/av58778425
课程作业：https://github.com/Burton2000/CS231n-2017

<!--more-->

## Lecture 1：引言
主要是计算机视觉概述和背景。
- 从1960年代末到2017年的计算机视觉简史。
- 计算机视觉问题包括图像分类，目标定位，目标检测和场景理解。
- Imagenet是目前可用的图像分类中最大的数据集之一。
- 从2012年在Imagenet竞赛中开始，CNN（卷积神经网络）一直是赢家。
- CNN实际上是由Yann Lecun于1997年发明的。
- 近年来深度学习的成功主要来源于数据和算力的增长

## Lecture 2：图像分类
### 数据驱动
数据驱动的分类方法是指:
- 收集具有标注的图片数据集(CIFAR10).
- 使用机器学习来训练分类器.
- 使用模型来预测新的图片.

### KNN
KNN用于图片分类：将两张图片先转化为两个向量（向量的维度为像素数量）$I_1$和$I_2$，再计算两者的距离$L_1$或者$L_2$（距离的选择是一个超参数），找距离最近的k个图片的标签，让他们针对测试图片进行投票，把票数最高的标签作为对测试图片的预测。
#### 距离函数
距离函数是K近邻算法的关键.常用的有L1距离,L2距离等.通过不同的距离函数还可以将K近邻算法泛化到任何类型的数据上.
![](https://i.loli.net/2019/09/24/Mv4KWftwbTCBlgu.png)

#### K值
K指的是邻居的个数，可以使用交叉验证调优。

#### 超参数选择
K近邻算法中的K值和距离函数就是典型的超参数:需要人为设置,而不能由算法学习得到.选择超参数的常见作法就是将数据集分为训练集,验证集,测试集.使用验证集来选择超参数,并在测试集得到结果.如果数据集较小,还可以采用交叉验证的方法进行选择.
**划分数据集**
![](https://i.loli.net/2019/09/24/nm9aGqfFD3Q4KgV.png)
**交叉验证**
![](https://i.loli.net/2019/09/24/nybgcoX8Vsi3fUE.png)
**交叉验证选择K值**
![](https://i.loli.net/2019/09/24/zZ7PIpEK8xCwS9k.png)

#### 缺点
- 测试要花费大量时间计算，因为每个测试图像需要和所有存储的训练图像进行比较（Train $$O(1)$$ , Test $$O(n)$$）
- 图像的分类是基于背景的，而不是图片的语义主体。

## Lecture 3：损失函数和优化
## Lecture 4：反向传播与神经网络
## Lecture 5：卷积神经网络
## Lecture 6：如何训练神经网络 I
## Lecture 7：如何训练神经网络 II
## Lecture 8: 深度学习软件
## Lecture 9：卷积神经网络架构
## Lecture 10：循环神经网络
## Lecture 11：检测与分割
## Lecture 12：可视化和理解
## Lecture 13：生成模型
## Lecture 14：强化学习
## Lecture 15：深度学习高效的方法和硬件
## Lecture 16：对抗性样本和对抗性训练



