---
title: 最大似然估计和最大后验估计
tags: 机器学习
abbrlink: 46328
date: 2019-07-22 12:31:19
---

![](https://i.loli.net/2019/07/22/5d357cfaebdc553807.png)

图片来自[网站](https://www.xkcd.com/1132/)

- 频率学派 - Frequentist - Maximum Likelihood Estimation (MLE，最大似然估计)
- 贝叶斯学派 - Bayesian - Maximum A Posteriori (MAP，最大后验估计)

<!--more-->

## 问题引入
已知一组数据集 $D={x_1,x_2,...,x_n}$ 是独立地从概率分布 $P(x)$ 上采样生成的，且 $P(x)$ 具有确定的形式（如高斯分布，二项分布等）但参数 $\theta$ 未知。

**问题：如何根据数据集 $D$ 估计参数 $\theta$ ?**

为了解决上述问题，统计学界存在两种不同的解决方案：

- **频率学派**：**参数 $\theta$ 是一个客观存在的固定值**，其可以通过找到使数据集 $D$ 出现可能性最大的值，对参数 $\theta$ 进行估计，此便是极大似然估计的核心思想。
- **贝叶斯学派**：**参数 $\theta$ 是一个随机变量，服从一个概率分布**，其首先根据主观的经验假定 $\theta$ 的概率分布为 $P(\theta)$（先验分布，往往并不准确），然后根据观察到的新信息（数据集 $D$ ）对其进行修正，此时 $\theta$ 的概率分布为 $p(\theta|D)$（后验分布）。

## 最大似然估计
Maximum Likelihood Estimation, MLE是频率学派常用的估计方法。
核心思想：找到使数据集 $D$ 出现可能性最大的值，对参数 $D$ 进行估计，即:
$$
\begin{aligned} \hat{\theta}_{\mathrm{MLE}} &=\underset{\arg \max } P(X ; \theta) \\ &=\arg \max P\left(x_{1} ; \theta\right) P\left(x_{2} ; \theta\right) \cdots P\left(x_{n} ; \theta\right) \\ &=\arg \max \log \prod_{i=1}^{n} P\left(x_{i} ; \theta\right) \\ &=\arg \max \sum_{i=1}^{n} \log P\left(x_{i} ; \theta\right) \\ &=\arg \min -\sum_{i=1}^{n} \log P\left(x_{i} ; \theta\right) \end{aligned}
$$
最后这一行所优化的函数被称为Negative Log Likelihood。深度学习做分类任务时所用的cross entropy loss，其本质也是MLE。
## 最大后验估计
Maximum A Posteriori, MAP是贝叶斯学派常用的估计方法。
原则上，贝叶斯学派对 $\theta$ 的估计应该就是 $\theta$ 的后验分布 $p(\theta|D)$ ，但是大多数时候后验分布的计算较为棘手，因此此时出现一种折衷解法：找到使后验概率最大的值，对参数 $\theta$ 进行估计，即:
$$
\begin{aligned} \hat{\theta}_{\mathrm{MAP}} &=\arg \max P(\theta | X) \\ &=\arg \min -\log P(\theta | X) \\ &=\arg \min -\log P(X | \theta)-\log P(\theta)+\log P(X) \\ &=\arg \min -\log P(X | \theta)-\log P(\theta) \end{aligned}

$$
其中，第二行到第三行使用了贝叶斯定理，第三行到第四行 $P(X)$可以丢掉因为与 $\theta$ 无关。

注意到 $-\log P(X | \theta)$ 就是Negative Log Likelihood，所以MLE和MAP在优化时的不同就是在于先验项
$-\log P(\theta)$。假定先验是一个高斯分布，
$$
P(\theta)=\text { constant } \times e^{-\frac{\theta^{2}}{2 \sigma^{2}}}
$$
那么:
$$
-\log P(\theta)=\text { constant }+\frac{\theta^{2}}{2 \sigma^{2}}
$$
此时在MAP中使用一个高斯分布的先验等价于在MLE中采用L2的regularizaton。
如果在MAP中使用一个拉普拉斯分布的先验，即：
$$
P\left(\theta\right)=\frac{1}{\sqrt{2 a}} e^{\frac{-\left|\theta\right|}{a}}
$$
则有：
$$
\log P(\theta)=\log \prod_{j} \frac{1}{\sqrt{2 a}} e^{\frac{-|\theta|}{a}}=-\frac{1}{a} \sum_{j}\left|\theta\right|+C^{\prime}
$$
可以看到，在拉普拉斯分布下的效果等价于在代价函数中增加 L1正则项。


## 说明
- 随着数据量的增加，参数分布会越来越向数据靠拢，先验的影响力会越来越小
- 如果先验是uniform distribution，则贝叶斯方法等价于频率方法。因为直观上来讲，先验是uniform distribution本质上表示对事物没有任何预判

## 总结
至此，在深入理解了频率学派和贝叶斯学派之后，终于把L1和L2正则化技术，MLP和MAP，以及生成式判别式模型联系起来了。
- 所谓MAP就是在MLP的基础上加了一项先验分布。（当然背后的思想不一样）
- 如果先验分布是均匀分布，两者一致
- 如果先验分布是高斯分布，那么等价于增加了L2正则
- 如果先验是拉普拉斯分布，那么等价与增加了L1正则
- 频率思想下指导的判别式模型，贝叶斯思想指导下的是生成模型。
- 频率派衍生出来的是统计机器学习模型，最终转换为一个优化问题。贝叶斯派衍生出来的是概率图模型，最终转换为一个积分问题。


